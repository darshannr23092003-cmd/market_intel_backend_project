Market Intelligence Multi-Agent System (MCP Architecture)
A modular multi-agent system that generates structured market intelligence reports using local open-source LLMs (Ollama)[used tinyllama in this project] and MCP Tool Server architecture.
This project implements a full pipeline of autonomous agents â€” Collector, Extractor, Impact, and Writer â€” that interact only via MCP tools, following a real agent-tool architecture.


Architecture Overview:

market_intel/
â”‚
â”œâ”€â”€ api/                  # FastAPI application (public interface)
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ agents/               # Autonomous agents
â”‚   â”œâ”€â”€ collector.py
â”‚   â”œâ”€â”€ extractor.py
â”‚   â”œâ”€â”€ impact.py
â”‚   â””â”€â”€ writer.py
â”‚
â”œâ”€â”€ mcp_server/           # MCP Tool Server (tool execution layer)
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ tools.py
â”‚
â”œâ”€â”€ pipeline.py           # Orchestrates full agent workflow

Features

Multi-agent pipeline:
Collector â†’ generates search queries
Extractor â†’ extracts competitors & themes
Impact â†’ generates impact scores
Writer â†’ produces final market report
MCP Tool Server abstraction layer
Fully local inference using Ollama (no paid APIs)
Deterministic fallbacks (project never crashes)
JSON-only structured outputs

Requirements

Python 3.10+
Ollama installed locally
ðŸ‘‰ https://ollama.com/download

A lightweight model pulled:
ollama pull tinyllama

Installation

git clone https://github.com/your-username/market_intel.git
cd market_intel

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install fastapi uvicorn httpx requests

Running the System
Terminal 1 â€” Start MCP Tool Server

uvicorn mcp_server.server:app --port 8001 --reload

Verify:
curl http://127.0.0.1:8001/health

Terminal 2 â€” Start Main API Server
uvicorn api.main:app --port 8000 --reload

Open Swagger UI:
http://127.0.0.1:8000/docs

Models Used

All inference is performed locally using:
tinyllama (Ollama)
No OpenAI, no closed-source APIs.
Fully compliant with open-source requirement.




